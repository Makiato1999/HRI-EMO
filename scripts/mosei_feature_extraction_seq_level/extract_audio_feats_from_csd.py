#!/usr/bin/env python3
import argparse
from pathlib import Path
import json

import numpy as np
import torch
import pandas as pd
from mmsdk import mmdatasdk


def parse_args():
    ap = argparse.ArgumentParser()
    ap.add_argument(
        "--data_root",
        type=str,
        default="data/MOSEI",
        help="Folder with CMU_MOSEI_Labels.csd & CMU_MOSEI_COVAREP.csd",
    )
    ap.add_argument(
        "--index_csv",
        type=str,
        default="data/mosei_index_splits.csv",
        help="Index CSV generated by build_mosei_index_splits.py",
    )
    ap.add_argument(
        "--out_dir",
        type=str,
        default="features/mosei/seq_level/audio",
        help="Output dir for seq-level audio features",
    )
    return ap.parse_args()


def main():
    args = parse_args()

    data_root = Path(args.data_root)
    out_dir = Path(args.out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    index_path = Path(args.index_csv)
    if not index_path.exists():
        raise FileNotFoundError(
            f"{index_path} not found. 请先运行 build_mosei_index_splits.py。"
        )

    label_csd = data_root / "CMU_MOSEI_Labels.csd"
    covarep_csd = data_root / "CMU_MOSEI_COVAREP.csd"

    if not label_csd.exists():
        raise FileNotFoundError(
            f"{label_csd} not found.\n"
            f"请把 CMU_MOSEI_Labels.csd 放在 {data_root} 下，"
            f"或用 --data_root 指向正确目录。"
        )
    if not covarep_csd.exists():
        raise FileNotFoundError(
            f"{covarep_csd} not found.\n"
            f"请把 CMU_MOSEI_COVAREP.csd 放在 {data_root} 下，"
            f"或用 --data_root 指向正确目录。"
        )

    print(
        f"[Info] Loading local CSDs from {data_root} "
        f"(audio + labels only, no HTTP)"
    )

    # 只用本地文件，不给远程 URL
    recipe = {
        "CMU_MOSEI_Labels": str(label_csd.resolve()),
        "CMU_MOSEI_COVAREP": str(covarep_csd.resolve()),
    }
    ds = mmdatasdk.mmdataset(recipe)

    label_key = "CMU_MOSEI_Labels"
    audio_key = "CMU_MOSEI_COVAREP"

    label_data = ds.computational_sequences[label_key].data
    audio_data = ds.computational_sequences[audio_key].data

    print(
        f"[Info] Loaded labels for {len(label_data)} videos, "
        f"audio for {len(audio_data)} videos"
    )

    df = pd.read_csv(index_path)

    saved = 0
    feat_dim = None

    # 主循环：按照 CSV 里的 (video_id, seg_idx)，用 label 的时间戳在 COVAREP 里截片
    for _, row in df.iterrows():
        vid = row["video_id"]
        seg_idx = int(row["seg_idx"])
        uid = row["uid"]

        if vid not in label_data or vid not in audio_data:
            # 该视频在某一模态缺失，跳过
            continue

        # ---------- 从 label 取该 segment 的时间范围 ----------
        lbl = label_data[vid]
        lbl_intervals = lbl["intervals"]  # [num_segs, 2]
        if seg_idx >= lbl_intervals.shape[0]:
            continue
        seg_start, seg_end = lbl_intervals[seg_idx]

        # ---------- 在 audio 里按时间戳找落在这个 segment 的帧 ----------
        au = audio_data[vid]
        au_feats = au["features"]       # [T, D]
        au_intervals = au["intervals"]  # [T, 2]

        if au_feats.size == 0 or au_intervals.size == 0:
            continue

        # 用帧中心点在 [seg_start, seg_end] 内来选
        centers = (au_intervals[:, 0] + au_intervals[:, 1]) / 2.0
        mask = (centers >= seg_start) & (centers <= seg_end)

        # 如果一个都没选到，用区间重叠兜底一下
        if not mask.any():
            mask = (au_intervals[:, 0] < seg_end) & (au_intervals[:, 1] > seg_start)

        if not mask.any():
            # 这个 seg 在音频模态下没有帧，直接跳过
            continue

        seg_feats = au_feats[mask]  # [L, D]
        # 没有对 seg_feats 做任何 NaN / Inf 清洗。而 MOSEI 的 COVAREP 里是已知会出现 NaN 的（某些声学特征提取不到）。
        # 所以如果哪怕一个 frame 的某个维度是 NaN，它就被完整写进 [uid].pt，后面：进模型 → 注意力 / 线性层 → 全是 NaN
        # 最后 BCEWithLogitsLoss 收到 NaN → loss 变 NaN
        # NEW: 清洗 NaN / Inf
        seg_feats = np.nan_to_num(seg_feats, nan=0.0, posinf=0.0, neginf=0.0)
        
        if seg_feats.ndim == 1:
            seg_feats = seg_feats[None, :]

        h = torch.from_numpy(seg_feats).float()
        L, D = h.shape

        if feat_dim is None:
            feat_dim = D

        attn = torch.ones(L, dtype=torch.long)

        torch.save(
            {
                "hidden": h,
                "attention_mask": attn,
            },
            out_dir / f"{uid}.pt",
        )
        saved += 1

    meta = {
        "source": audio_key,
        "hidden_dim": feat_dim,
        "num_segments": saved,
        "note": (
            "MOSEI audio seq-level features from COVAREP, "
            "per (video_id, seg_idx) using label intervals from mosei_index_splits.csv. "
            "No global align() to避免内存爆炸。"
        ),
    }
    (out_dir / "meta.json").write_text(json.dumps(meta, indent=2), encoding="utf-8")

    print(f"[OK] Saved {saved} audio seq-level features to {out_dir}")


if __name__ == "__main__":
    main()
