{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbYT251AAVGw",
        "outputId": "90558fc5-15ab-4e46-850a-5fd4fde6cfb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "Fri Nov 28 22:47:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   42C    P8             16W /   72W |       3MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch, os, platform, sys\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihXwSg95CLPI",
        "outputId": "eab7480c-eaa4-4290-9626-7d9d265eb191"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content\n",
        "\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/beta_decoder_project/mosei_features_and_index.zip .\n",
        "!unzip -q mosei_features_and_index.zip -d ."
      ],
      "metadata": {
        "id": "RMyMYehICaHB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sync Github repo\n",
        "\n",
        "!rm -rf /content/HRI-EMO\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/Makiato1999/HRI-EMO.git\n",
        "%cd HRI-EMO\n",
        "\n",
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej9A-BbINHEP",
        "outputId": "c4593004-716e-4f15-b535-35c51ac9423f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'HRI-EMO'...\n",
            "remote: Enumerating objects: 363, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 363 (delta 31), reused 42 (delta 18), pack-reused 303 (from 1)\u001b[K\n",
            "Receiving objects: 100% (363/363), 910.58 KiB | 36.42 MiB/s, done.\n",
            "Resolving deltas: 100% (207/207), done.\n",
            "/content/HRI-EMO\n",
            "/content/HRI-EMO\n",
            "models\tnotebooks  README.md  scripts  tests  tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def check_modality(name, relative_path):\n",
        "    print(f\"ðŸ”Ž Checking {name} ...\")\n",
        "\n",
        "    # Assuming current dir is /content/HRI-EMO, so use ../features\n",
        "    dir_path = Path(relative_path)\n",
        "\n",
        "    if not dir_path.exists():\n",
        "        print(f\"âŒ Path does not exist: {dir_path.resolve()}\")\n",
        "        return False, \"PathNotFound\"\n",
        "\n",
        "    try:\n",
        "        # Get the first .pt file found\n",
        "        files = list(dir_path.glob(\"*.pt\"))\n",
        "        if not files:\n",
        "            print(f\"âŒ No .pt files found in directory: {dir_path}\")\n",
        "            return False, \"NoFiles\"\n",
        "\n",
        "        sample_file = files[0]\n",
        "        data = torch.load(sample_file, map_location=\"cpu\")\n",
        "        data_type = type(data)\n",
        "\n",
        "        if isinstance(data, dict):\n",
        "            keys = list(data.keys())\n",
        "            if \"hidden\" in data:\n",
        "                print(f\"âœ… [PASS] Format: Dict | Keys: {keys}\")\n",
        "                return True, \"DictWithHidden\"\n",
        "            else:\n",
        "                print(f\"âš ï¸ [WARNING] Format: Dict | âŒ Missing 'hidden' key | Keys: {keys}\")\n",
        "                return False, \"DictNoHidden\"\n",
        "\n",
        "        elif isinstance(data, torch.Tensor):\n",
        "            print(f\"âš ï¸ [WARNING] Format: Tensor | Shape: {data.shape}\")\n",
        "            return False, \"Tensor\"\n",
        "\n",
        "        else:\n",
        "            print(f\"âŒ [ERROR] Unknown format: {data_type}\")\n",
        "            return False, \"Unknown\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Read Error: {e}\")\n",
        "        return False, \"Error\"\n",
        "\n",
        "# ================= Run Check =================\n",
        "print(\"=\"*40)\n",
        "# 1. Check Audio\n",
        "audio_ok, audio_status = check_modality(\"Audio\", \"../features/mosei/seq_level/audio\")\n",
        "print(\"-\" * 20)\n",
        "# 2. Check Text\n",
        "text_ok, text_status = check_modality(\"Text\", \"../features/mosei/seq_level/text\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# ================= Final Conclusion =================\n",
        "print(\"\\nðŸ“¢ Final Conclusion:\")\n",
        "if audio_ok and text_ok:\n",
        "    print(\"ðŸŸ¢ Perfect! Both Audio and Text are standard Dict formats containing 'hidden'.\")\n",
        "    print(\"ðŸš€ You can run train.py directly. No code changes needed!\")\n",
        "else:\n",
        "    print(\"ðŸ”´ Formats are inconsistent or non-standard.\")\n",
        "    print(\"ðŸ›  Please modify the _load_feat function in train.py using the 'Compatible Version' code I provided earlier.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TysR_-rApy4y",
        "outputId": "7276d584-0dac-4871-d0b6-d3765bc78e92"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "ðŸ”Ž Checking Audio ...\n",
            "âœ… [PASS] Format: Dict | Keys: ['hidden', 'attention_mask']\n",
            "--------------------\n",
            "ðŸ”Ž Checking Text ...\n",
            "âœ… [PASS] Format: Dict | Keys: ['hidden', 'attention_mask']\n",
            "========================================\n",
            "\n",
            "ðŸ“¢ Final Conclusion:\n",
            "ðŸŸ¢ Perfect! Both Audio and Text are standard Dict formats containing 'hidden'.\n",
            "ðŸš€ You can run train.py directly. No code changes needed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install tqdm pandas numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so6c0XiQOhjh",
        "outputId": "8f9611a8-68ad-4f01-84a8-79692ed11503"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "\n",
        "# Check if the repository is in /content/HRI-EMO\n",
        "print(\"ls /content ->\")\n",
        "print(os.listdir(\"/content\"))\n",
        "\n",
        "# If you see the 'HRI-EMO' folder, switch to it\n",
        "os.chdir(\"/content/HRI-EMO\")\n",
        "print(\"âœ… cwd:\", os.getcwd())\n",
        "\n",
        "# Ensure the project's 'models' package can be imported\n",
        "sys.path.append(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0M9wHWzRzhm",
        "outputId": "2789c7b5-2435-460b-fc07-9a19805f9a52"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls /content ->\n",
            "['.config', 'drive', 'mosei_features_and_index.zip', 'data', 'features', 'HRI-EMO', 'sample_data']\n",
            "âœ… cwd: /content/HRI-EMO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Training / Retraining Section\n",
        "# ==========================================\n",
        "%cd /content/HRI-EMO\n",
        "\n",
        "# ------------------------------------------\n",
        "# [DEPRECATED] v1 Configuration: Initial Run\n",
        "# Status: Overfitting observed (High Train AUC, Low Val Performance).\n",
        "# Issues: Model too complex (2 layers, d_model=384) for MOSEI size.\n",
        "# ------------------------------------------\n",
        "# !python -m scripts.fusion.train_mosei_fusion_seq_level_decoder \\\n",
        "#   --index_csv ../data/mosei_index_splits.csv \\\n",
        "#   --audio_dir ../features/mosei/seq_level/audio \\\n",
        "#   --text_dir ../features/mosei/seq_level/text \\\n",
        "#   --epochs 20 \\\n",
        "#   --batch_size 8 \\\n",
        "#   --grad_accum 4 \\\n",
        "#   --warmup_ratio 0.1 \\\n",
        "#   --beta_entropy 1e-3 \\\n",
        "#   --max_len_audio 300 \\\n",
        "#   --max_len_text 128 \\\n",
        "#   --d_model 384 \\\n",
        "#   --n_heads 6 \\\n",
        "#   --num_layers_fusion 2 \\\n",
        "#   --num_layers_decoder 2 \\\n",
        "#   --dropout 0.2 \\\n",
        "#   --lr 1e-4 \\\n",
        "#   --weight_decay 1e-2 \\\n",
        "#   --num_workers 2 \\\n",
        "#   --select_by macro_auc \\\n",
        "#   --save_calibrated_ths \\\n",
        "#   --out_dir /content/drive/MyDrive/ColabNotebooks/beta_decoder_project/HRI-EMO-results/mosei_fusion_decoder_small \\\n",
        "#   --seed 1234\n",
        "\n",
        "# ------------------------------------------\n",
        "# [RECOMMENDED] v2 Configuration: Optimized for Generalization\n",
        "# Status: Stable. Solved overfitting via strong regularization.\n",
        "# Key Changes:\n",
        "#   1. Simplified Architecture: 1 Fusion Layer, d_model=256, beta_hidden=64.\n",
        "#   2. Stronger Regularization: Dropout=0.4, Weight Decay=0.05.\n",
        "#   3. Metrics: Checkpointing based on 'calibrated_macro_f1' instead of AUC.\n",
        "# Note: Uncomment below to run here, or use 'mosei_train.ipynb'.\n",
        "# ------------------------------------------\n",
        "!python -m scripts.fusion.train_mosei_fusion_seq_level_decoder \\\n",
        "  --index_csv ../data/mosei_index_splits.csv \\\n",
        "  --audio_dir ../features/mosei/seq_level/audio \\\n",
        "  --text_dir ../features/mosei/seq_level/text \\\n",
        "  --out_dir /content/drive/MyDrive/ColabNotebooks/beta_decoder_project/HRI-EMO-results/mosei_fusion_decoder_v2 \\\n",
        "  --epochs 20 \\\n",
        "  --batch_size 16 \\\n",
        "  --grad_accum 2 \\\n",
        "  --lr 5e-5 \\\n",
        "  --weight_decay 0.05 \\\n",
        "  --dropout 0.4 \\\n",
        "  --d_model 256 \\\n",
        "  --n_heads 4 \\\n",
        "  --num_layers_fusion 1 \\\n",
        "  --num_layers_decoder 2 \\\n",
        "  --beta_hidden 64 \\\n",
        "  --beta_entropy 1e-3 \\\n",
        "  --warmup_ratio 0.1 \\\n",
        "  --select_by calibrated_macro_f1 \\\n",
        "  --save_calibrated_ths \\\n",
        "  --seed 1234"
      ],
      "metadata": {
        "id": "B4n7brloOtaz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}